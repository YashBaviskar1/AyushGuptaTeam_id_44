import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

# Load the dataset
data = pd.read_csv('/content/merged_file.csv')  # Make sure to replace 'your_dataset.csv' with the actual file path

# Preprocess the data
scaler = MinMaxScaler()
scaled_data = scaler.fit_transform(data[['Air temperature', 'Pressure', 'Wind speed', 'Power generated by system']])

# Define sequence length (number of time steps to look back)
seq_length = 3  # You can adjust this value based on your preference

# Create sequences of data with the specified sequence length
sequences = []
for i in range(len(scaled_data) - seq_length):
    sequences.append(scaled_data[i:i+seq_length+1])

# Convert sequences to numpy array
sequences = np.array(sequences)

# Split the data into features and target
X = sequences[:, :-1]  # Features (all columns except the last one)
y = sequences[:, -1][:, -1]  # Target (last column)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Build the LSTM model
model = Sequential()
model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(LSTM(50, return_sequences=False))
model.add(Dense(1))

# Compile the model
model.compile(optimizer='adam', loss='mse')

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))